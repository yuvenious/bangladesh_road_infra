{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, cos, sin, sqrt, atan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function defines the distance between two locations.\n",
    "def distance(loc1, loc2, R = 6380):\n",
    "    #change the value into radians\n",
    "    lat1 = radians(float(loc1[0]))\n",
    "    lon1 = radians(float(loc1[1]))\n",
    "    \n",
    "    lat2 = radians(float(loc2[0]))\n",
    "    lon2 = radians(float(loc2[1]))\n",
    "    \n",
    "    #calculate the distance\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = (sin(dlat/2))**2 + cos(lat1) * cos(lat2) * (sin(dlon/2))**2\n",
    "    c = 2 * atan2( sqrt(a), sqrt(1-a) )\n",
    "    d = R * c # where R is the radius of the Earth\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load road and bridge data (N1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"_roads3.csv\")\n",
    "df_r = df[df[\"road\"] == \"N1\"][:]\n",
    "df = pd.read_excel(\"BMMS_overview.xlsx\")\n",
    "df_b = df[df[\"road\"] == \"N1\"][:]\n",
    "dup = (df_b.sort_values(\"km\").duplicated(\"km\", keep = \"first\")\n",
    "       |\n",
    "       df_b.sort_values(\"km\").duplicated(\"km\", keep = \"last\"))\n",
    "df_b.loc[dup].sort_values(\"km\")\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "for i in range(len(df_b.loc[dup][\"km\"].unique())):\n",
    "    df_ele = df_b.loc[dup][df_b.loc[dup][\"km\"] == df_b.loc[dup][\"km\"].unique()[i]]\n",
    "    df_ele.fillna(method = \"ffill\", inplace = True)\n",
    "    df_ele.fillna(method = \"bfill\", inplace = True)\n",
    "\n",
    "    new_df = pd.concat([new_df, df_ele])\n",
    "# drop duplicates and keep the lower entry, as they are assumed to be recored more recent.\n",
    "df_b = df_b.drop_duplicates(\"km\", keep = \"last\").sort_values(\"km\")\n",
    "\n",
    "# Select Dhaka ~ Chittagong\n",
    "df_r = df_r.iloc[:565]\n",
    "df_b = df_b.iloc[:162]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert road/bridge data into the form readable in Simio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\markhupkens\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "def create_data(df_r, df_b, nrow = False):\n",
    "    \"\"\"\n",
    "    Extract necessary information from road/bridge data\n",
    "    1. Type (Bridge/Road), LRP\n",
    "    2. Longitude, Latitude, Chainage, Distance\n",
    "    3. Bridge condition(A/B/C/D) and length\n",
    "    \"\"\"\n",
    "    road = pd.concat([df_r[[\"lon\", \"lat\", \"chainage\", \"lrp\"]],\n",
    "                      pd.DataFrame((\"Road \"*len(df_r)).split(), columns = [\"type\"])], axis = 1)\n",
    "\n",
    "    bridge = df_b[[\"lon\", \"lat\", \"chainage\", \"LRPName\", \"length\", \"condition\", \"length\"]]\n",
    "    bridge.columns = ['lon', 'lat', 'chainage', 'lrp', 'BriLen', 'BriCond', 'type']\n",
    "    bridge[\"type\"] = \"Bridge\"\n",
    "    \n",
    "    transfernode = pd.DataFrame(data = bridge.values, index = bridge.index, columns = bridge.columns)\n",
    "    transfernode[\"type\"] = \"Output@Bridge\"\n",
    "    transfernode[\"BriLen\"] = None\n",
    "\n",
    "    df = pd.concat([road, bridge, transfernode]).sort_values(by = [\"chainage\", \"type\"])\n",
    "    df.reset_index(inplace = True)\n",
    "    df[\"Object Name\"] = df[\"lrp\"].values\n",
    "    df[\"Object Name\"] = df[[\"type\", \"Object Name\"]].apply(lambda x: \"\".join([\"Output@Bridge\", x[1]])\n",
    "                                                          if x[0][0] == \"O\"\n",
    "                                                          else x[1],axis = 1).values\n",
    "    \n",
    "    df[\"Object Name\"] = df[[\"type\", \"Object Name\"]].apply(lambda x: \"\".join([\"Bridge\", x[1]])\n",
    "                                                          if x[0] == \"Bridge\"\n",
    "                                                          else x[1],axis = 1).values\n",
    "    \n",
    "    df[\"distance\"] = [1e3 * distance(df[[\"lat\", \"lon\"]].iloc[i],\n",
    "                                     df[[\"lat\", \"lon\"]].iloc[i+1]) for i in range(len(df) - 1)] + [None]\n",
    "    if type(nrow) == int:\n",
    "        df = df.loc[:nrow]\n",
    "    elif not nrow:\n",
    "        df = df\n",
    "    return df\n",
    "data = create_data(df_r, df_b, 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\markhupkens\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "231634.91190303524"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_data(df_r, df_b)[\"distance\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 35 Segments â†’ 4 Segments (Highly Aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_traffic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-194b45b83893>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf_traffic\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mdf_traffic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_traffic' is not defined"
     ]
    }
   ],
   "source": [
    "def agg_segments(df_traffic, idx = [0,6,23,25,36]):\n",
    "    # segment starts/ends\n",
    "    seg_start = idx[:-1]\n",
    "    seg_end = idx[1:]\n",
    "    func = np.vectorize(lambda x: x in seg_start)\n",
    "    seg_start = func(df_traffic.index.values)\n",
    "    func = np.vectorize(lambda x: x in seg_end)\n",
    "    seg_end = func(df_traffic.index.values)\n",
    "    seg_end[-1] = True\n",
    "    df_traffic[\"seg_start\"] = seg_start\n",
    "    df_traffic[\"seg_end\"] = seg_end\n",
    "    \n",
    "    # assign segments\n",
    "    df_traffic[\"segment\"] = np.repeat(range(1,5), np.diff(np.array(idx)))\n",
    "    seg_ori = np.array(df_traffic[\"Link No\"].values)\n",
    "    seg_new = \"N1_\" + df_traffic[\"segment\"].values.astype(str).astype(object)\n",
    "    df_traffic[\"Link No\"] = seg_new\n",
    "    df_traffic[\"segment\"] = seg_ori\n",
    "    return df_traffic\n",
    "\n",
    "df_traffic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Road Segments (Traffic Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def add_segments(df_r, df_b, traffic_file = \"N1_traffic.csv\", n = 35):\n",
    "#     n=35: Dhaka~Chittagong\n",
    "    df_traffic = pd.read_csv(traffic_file, index_col = 0).loc[:n]\n",
    "#     Aggregate into 4 Segments\n",
    "    df_traffic = agg_segments(df_traffic)\n",
    "#     Load Road, Bridge Data\n",
    "    data = create_data(df_r, df_b)\n",
    "#     Start building!\n",
    "    df = pd.DataFrame(data = data.values, columns = data.columns)    \n",
    "#     Boolean (whether segment starts/ends)\n",
    "    seg_start = df_traffic[df_traffic[\"seg_start\"]][\"Chainage_Start\"].values\n",
    "    seg_end = df_traffic[df_traffic[\"seg_end\"]][\"Chainage_Start\"].values\n",
    "    seg_end = np.append(seg_end[:-1], df[\"chainage\"].tail(1).values)\n",
    "    seg = np.append(seg_start, seg_end[-1])\n",
    "    \n",
    "    df[\"seg_start\"] = df[\"chainage\"].apply(lambda x: x in seg_start).values\n",
    "    df[\"seg_end\"] = df[\"chainage\"].apply(lambda x: x in seg_end).values\n",
    "\n",
    "#     if a segment starts (or ends) -> node\n",
    "#     if not -> vertice\n",
    "    df[\"vertice\"] = df[\"chainage\"].apply(lambda x: \"transfernode\" if x in seg else \"vertice\").values\n",
    "    \n",
    "#     Bridge\n",
    "    idx_bridge = df.index[df[\"type\"].apply(lambda x: x == \"Bridge\")]\n",
    "#     Bridge is bridge\n",
    "    df.loc[idx_bridge, \"vertice\"] = \"bridge\"\n",
    "#     neighboring point to bridge -> node\n",
    "    df.loc[idx_bridge - 1, \"vertice\"] = \"basicnode\"\n",
    "    df.loc[idx_bridge + 1, \"vertice\"] = \"basicnode\"\n",
    "    \n",
    "    df.loc[df.index[df[\"seg_start\"]],\"vertice\"] = \"transfernode\"\n",
    "    df.loc[df.index[df[\"seg_end\"]],\"vertice\"] = \"transfernode\"\n",
    "    \n",
    "#     Paths which have to be made in Simio\n",
    "    paths = []\n",
    "    i = 0\n",
    "    for val in df[\"vertice\"].values:\n",
    "        if val in [\"transfernode\", \"basicnode\"] :\n",
    "            i = i + 1\n",
    "        paths.append(str(i))\n",
    "#     Give a name to each path (Path0, Path1, Path2,...)\n",
    "    df[\"path\"] = np.repeat(\"Path\", len(paths)).astype(np.object) + np.array(paths, dtype=np.object)\n",
    "    \n",
    "#     distance value of vertice -> aggregate into node\n",
    "    d = {}\n",
    "    for path in df[\"path\"].unique():\n",
    "        idx = df.index[df[\"path\"] == path]\n",
    "        df_dis = df.loc[idx, \"distance\"]\n",
    "        dis = df_dis.sum()\n",
    "        d[path] = dis\n",
    "    df[\"distance\"] = df[\"path\"].map(d)\n",
    "    df = df.reset_index(drop = True)\n",
    "#     print(df_traffic[[\"Link No\", \"segment\"]])\n",
    "#     Set segments\n",
    "    n_seg = df_traffic[\"Link No\"].nunique()\n",
    "    where_start_end = df[\"seg_start\"] | df[\"seg_end\"]\n",
    "    where_start_end = df[where_start_end].index\n",
    "    \n",
    "    n_repeat = np.diff(where_start_end)\n",
    "    n_repeat[-1] = n_repeat[-1] + 1 #compensate the last element\n",
    "    df[\"segment\"] = np.repeat(range(1,5),n_repeat)\n",
    "    # string join (\"1\" -> \"N1_1\")\n",
    "    df[\"segment\"] = df[\"segment\"].apply(lambda x: \"\".join([\"N1_\", str(x)]))\n",
    "    df_tra = df_traffic.iloc[:, [0]+list(range(9,25))].groupby(\"Link No\").mean().reset_index()\n",
    "    return pd.merge(df, df_tra, left_on = \"segment\", right_on=\"Link No\"), df_traffic[[\"Link No\", \"segment\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Function\n",
    "def create_link(data):\n",
    "    # data frame for creating object and link excel sheets\n",
    "    df_obj = data[data[\"vertice\"] != \"vertice\"]\n",
    "\n",
    "    # Blank data frame\n",
    "    col = \"Link Class;Link Name;From Node;To Node;Network;Type;DrawnToScale;LogicalLength\".split(\";\")\n",
    "    df_link = pd.DataFrame(columns=col)\n",
    "\n",
    "    # From node\n",
    "    df_link[\"From Node\"] = df_obj[df_obj[\"type\"] != \"Bridge\"][\"Object Name\"].values[:-1]\n",
    "    df_link[\"To Node\"] = df_obj[df_obj[\"type\"] != \"Bridge\"][\"Object Name\"].values[1:]\n",
    "    # Change string \"Bridge\" -> \"Input@Bridge\"\n",
    "    df_link[\"To Node\"] = df_link[\"To Node\"].apply(lambda x: \"\".join([\"Input\",x[6:]]) if x[0] == \"O\" else x).values\n",
    "\n",
    "    # assign values 1\n",
    "    df_link[\"Link Name\"] = df_obj[df_obj[\"type\"] != \"Bridge\"][\"path\"].values[:-1]\n",
    "    df_link[\"LogicalLength\"] = df_obj[df_obj[\"type\"] != \"Bridge\"][\"distance\"].values[:-1]\n",
    "    df_link[\"Network\"] = df_obj[df_obj[\"type\"] != \"Bridge\"][\"segment\"].values[:-1]\n",
    "\n",
    "    # assign values 2\n",
    "    df_link[\"Link Class\"] = \"Path\"\n",
    "    df_link[\"DrawnToScale\"] = \"False\"\n",
    "    df_link[\"Type\"] = \"Unidirectional\"\n",
    "    return df_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance Check (Fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231634.9119030353"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_link(data)[\"LogicalLength\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_obj(data, multi = 100, ng = -1):\n",
    "    # drop vertice\n",
    "    df_obj = data[data[\"vertice\"] != \"vertice\"]\n",
    "    # drop output@bridge\n",
    "    df_obj = df_obj[df_obj[\"type\"] != \"Output@Bridge\"]\n",
    "    \n",
    "    col = ['Object Class', 'Object Name', 'X', 'Y', 'Z', 'Length', 'Width', 'Height', 'BriLen', 'BriCond']\n",
    "    df_objs = pd.DataFrame(columns = col)\n",
    "    \n",
    "    df_objs[\"Object Class\"] = df_obj[\"vertice\"].apply(lambda x: \"TransferNode\" if x == \"transfernode\"\n",
    "                                                  else \"BasicNode\" if x == \"basicnode\"\n",
    "                                                  else \"Bridge\").values\n",
    "    df_objs[\"Object Name\"] = df_obj[\"Object Name\"].values\n",
    "\n",
    "    df_objs[\"X\"] = df_obj[\"lon\"].apply(lambda x: x * multi).values\n",
    "    df_objs[\"Y\"] = 0\n",
    "    df_objs[\"Z\"] = df_obj[\"lat\"].apply(lambda x: x * multi * ng).values\n",
    "    df_objs[\"BriLen\"] = df_obj[\"BriLen\"].values\n",
    "    df_objs[\"BriCond\"] = df_obj[\"BriCond\"].values\n",
    "    df_objs[\"EnteredAddOnProcess\"] = df_objs[\"Object Class\"].apply(lambda x: \"Process_StartPointSegment\"\n",
    "                                                               if x == \"TransferNode\"\n",
    "                                                               else np.nan)\n",
    "    return df_objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertice Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_vertice(data, multi = 100, ng = -1):\n",
    "    df_vertice = data[data[\"vertice\"] == \"vertice\"]\n",
    "    col = [\"Link Name\",\"Vertex X\", \"Vertex Y\",\"Vertex Z\"]\n",
    "    df_ver = pd.DataFrame(columns=col)\n",
    "    df_ver[\"Link Name\"] = df_vertice[\"path\"].values\n",
    "\n",
    "    df_ver[\"Vertex X\"] = df_vertice[\"lon\"].apply(lambda x: x * multi).values\n",
    "    df_ver[\"Vertex Y\"] = 0\n",
    "    df_ver[\"Vertex Z\"] = df_vertice[\"lat\"].apply(lambda x: x * multi * ng).values\n",
    "    return df_ver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "data, data_traffic = add_segments(df_r, df_b, traffic_file=\"N1_traffic.csv\")\n",
    "sheet_obj = create_obj(data, multi = 10000)\n",
    "sheet_link = create_link(data)\n",
    "sheet_vertice = create_vertice(data, multi = 10000)\n",
    "# save to excel file\n",
    "writer = pd.ExcelWriter('SimioObjects.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Write each dataframe to a different worksheet.\n",
    "sheet_obj.to_excel(writer, sheet_name='Objects1', index = False)\n",
    "sheet_link.to_excel(writer, sheet_name='Links1', index = False)\n",
    "sheet_vertice.to_excel(writer, sheet_name='Vertices1', index = False)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Segments and 35 segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_traffic[\"segment\"] = data_traffic[\"segment\"].apply(lambda x: \"\".join([x,\";\"])).values\n",
    "data_traffic = data_traffic.groupby(\"Link No\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_traffic[\"segment\"].apply(lambda x: x.split(\";\")).to_csv(\"agg_segment.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Distance of each Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogicalLength</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N1_1</th>\n",
       "      <td>15757.742678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N1_2</th>\n",
       "      <td>89256.084574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N1_3</th>\n",
       "      <td>32466.820604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N1_4</th>\n",
       "      <td>94154.264048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LogicalLength\n",
       "Network               \n",
       "N1_1      15757.742678\n",
       "N1_2      89256.084574\n",
       "N1_3      32466.820604\n",
       "N1_4      94154.264048"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet_link.groupby(\"Network\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Speed of Each Entity\n",
    "spd_truck = 5\n",
    "spd_bus = 6\n",
    "spd_other = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Network</th>\n",
       "      <th>LogicalLength</th>\n",
       "      <th>truck</th>\n",
       "      <th>bus</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N1_1</td>\n",
       "      <td>15757.742678</td>\n",
       "      <td>0.875430</td>\n",
       "      <td>0.729525</td>\n",
       "      <td>2.188575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N1_2</td>\n",
       "      <td>89256.084574</td>\n",
       "      <td>4.958671</td>\n",
       "      <td>4.132226</td>\n",
       "      <td>12.396678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N1_3</td>\n",
       "      <td>32466.820604</td>\n",
       "      <td>1.803712</td>\n",
       "      <td>1.503094</td>\n",
       "      <td>4.509281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N1_4</td>\n",
       "      <td>94154.264048</td>\n",
       "      <td>5.230792</td>\n",
       "      <td>4.358994</td>\n",
       "      <td>13.076981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Network  LogicalLength     truck       bus      other\n",
       "0    N1_1   15757.742678  0.875430  0.729525   2.188575\n",
       "1    N1_2   89256.084574  4.958671  4.132226  12.396678\n",
       "2    N1_3   32466.820604  1.803712  1.503094   4.509281\n",
       "3    N1_4   94154.264048  5.230792  4.358994  13.076981"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_time = sheet_link.groupby(\"Network\").sum().reset_index()\n",
    "expected_time[\"truck\"] = expected_time[\"LogicalLength\"] / spd_truck / 3600\n",
    "expected_time[\"bus\"] = expected_time[\"LogicalLength\"] / spd_bus / 3600\n",
    "expected_time[\"other\"] = expected_time[\"LogicalLength\"] / spd_other / 3600\n",
    "expected_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_time.to_csv(\"expected_time.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Tables (Segments, Tally, States)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_table(data, string):\n",
    "    table = data.loc[data[data[\"seg_end\"]].index - 1][\"path\"].reset_index()\n",
    "    table[\"lrp\"] = data[data[\"seg_start\"]][\"lrp\"].values\n",
    "    table[\"TimeInSys\"] = np.arange(1, 1+len(table)).astype(str)\n",
    "    table[\"TimeInSys\"] = table[\"TimeInSys\"].apply(lambda x: \"\".join([\"TalSeg\",x,\"_\"]))\n",
    "    table[\"NumInSys\"] = np.arange(1, 1+len(table)).astype(str)\n",
    "    table[\"NumInSys\"] = table[\"NumInSys\"].apply(lambda x: \"\".join([\"NumSeg\",x,\"_\"]))\n",
    "    table = table.drop(\"index\", axis = 1)\n",
    "    table.columns = [\"LastPath\", \"Start Node\", \"TimeInSys\", \"NumInSys\"]\n",
    "\n",
    "    table[\"TimeInSys\"] = table[\"TimeInSys\"].apply(lambda x: \"\".join([x, string]))\n",
    "    table[\"NumInSys\"] = table[\"NumInSys\"].apply(lambda x: \"\".join([x, string]))\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_table(data, \"Bus\").to_csv(\"table_bus.csv\", index = False)\n",
    "data_table(data, \"Truck\").to_csv(\"table_truck.csv\", index = False)\n",
    "data_table(data, \"Other\").to_csv(\"table_other.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Table\n",
    "    for creating transportations and distributing to every segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMALIZER is 3344.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bus</td>\n",
       "      <td>LRP016a</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bus</td>\n",
       "      <td>LRP108c</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bus</td>\n",
       "      <td>LRP142a</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bus</td>\n",
       "      <td>LRPS</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Truck</td>\n",
       "      <td>LRP016a</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Truck</td>\n",
       "      <td>LRP108c</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Truck</td>\n",
       "      <td>LRP142a</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Truck</td>\n",
       "      <td>LRPS</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>other</td>\n",
       "      <td>LRP016a</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>other</td>\n",
       "      <td>LRP108c</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>other</td>\n",
       "      <td>LRP142a</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>other</td>\n",
       "      <td>LRPS</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category Destination  Traffic\n",
       "0       Bus     LRP016a      2.0\n",
       "1       Bus     LRP108c      1.0\n",
       "2       Bus     LRP142a      2.0\n",
       "3       Bus        LRPS      4.0\n",
       "4     Truck     LRP016a      4.0\n",
       "5     Truck     LRP108c      3.0\n",
       "6     Truck     LRP142a      4.0\n",
       "7     Truck        LRPS      4.0\n",
       "8     other     LRP016a      1.0\n",
       "9     other     LRP108c      1.0\n",
       "10    other     LRP142a      1.0\n",
       "11    other        LRPS      3.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_table = pd.DataFrame(data.iloc[:, [8]][data[\"seg_start\"]].values,\n",
    "                              columns = [\"Destination\"])\n",
    "start = np.where(data.columns == \"Heavy Truck\")[0][0]\n",
    "transfer_table = transfer_table.merge(data.iloc[:, start:start+12][data[\"seg_start\"]].reset_index(drop = True), left_index = True, right_index = True)\n",
    "transfer_table = pd.DataFrame(transfer_table.set_index(\"Destination\").stack()).reset_index()\n",
    "transfer_table.columns = [\"Destination\", \"EntityType\", \"Traffic\"]\n",
    "transfer_table[\"EntityType\"].unique()\n",
    "transfer_table[\"category\"] = transfer_table[\"EntityType\"].apply(lambda x: \"Truck\" if \"Truck\" in x\n",
    "                                                                else \"Bus\" if \"Bus\" in x\n",
    "                                                                else \"other\" if \"Rickshaw\" in x\n",
    "                                                                else \"other\" if \"Cycle\" in x\n",
    "                                                                else np.nan)\n",
    "# Drop out-of-scope (Util, Car, Cart)\n",
    "transfer_table.dropna(inplace = True)\n",
    "transfer_table = transfer_table.groupby([\"category\", \"Destination\"]).sum().reset_index()\n",
    "# Normalize (Scale Down) by minimum value\n",
    "print(\"NORMALIZER is\", transfer_table[\"Traffic\"].min())\n",
    "transfer_table[\"Traffic\"] = transfer_table[\"Traffic\"].apply(lambda x: np.round(x/transfer_table[\"Traffic\"].min()))\n",
    "transfer_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transfer_table.to_csv(\"transfer_table.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
